

## Python Web Scrapper Script

To complete this assignment I programmed the web crawler using Python and an extended library called BeautifulSoup. The first section contains all the variables being declared, there are three main variables can be altered to modify the subject of the search, main search term, related terms and seed URLs. The next section is a function that is invoked only if the URL is considered relevant so, score > rank min. Score is the total of all related terms found in the document while rank min is the minimum number the terms should appear in order to be considered relevant. If a URL is relevant the function write_to_file() will write the URL, the URL score, and the number of its current position in the loop. Once a page is retrieved, the program focuses on the main portion of the content which is held in a div with a specific class name. This div is extracted, converted to a string and is then parsed to determine how many times the relative terms appear, which determines the score.

The crawler gathers links only when it needs to. For the first two seed pages, it saves all the relative links in the main body text. This block of code isn’t invoked again until the main loop runs out of seed URLs. This was done to save processing time and focus on the most relative links to the main search term.

## Python Inverted Index Script

For this assignment I used Python to complete this inverted index project. The program is comprised of three main functions: write to file, build frequency based index, build position based index, and an infinite loop for user interaction. I used two third party libraries, beautiful soup for data extraction and natural language tool kit (nltk) for tokenization and stop word removal. I also imported OS so the program can dynamically loop through all the files in the folder.

When the program first runs it will ask the user which type of index they would like to perform: Position based or Frequency, depending on the user’s selection it will perform the requested index function. During accuracy testing I noticed that looping through the directory was performed at random, determining the relationship of a document ID and the saved file was difficult, thus, I figured a relationship file should be created which is named, freq_page_link and pos_page_link. After the index function is complete the program then calls the write to file function which passes three arguments: the inverted index, the size of the index and the name of the file it should write. After the index is written to a file the program prompts the user asking if they would like to write the vocabulary list found in the data set. I created this since the vocabulary list will remain the same for either time an inverted index function is ran.  Once the write to file function is complete the program will prompt the user that the program in complete and will ask if the user will want to run another function.
